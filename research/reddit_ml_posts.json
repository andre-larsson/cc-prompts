[
  {
    "id": "1n67lft",
    "title": "[D] Self-Promotion Thread",
    "author": "AutoModerator",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1n67lft/d_selfpromotion_thread/",
    "text": "Please post your personal projects, startups, product placements, collaboration needs, blogs etc.\n\nPlease mention the payment and pricing requirements for products and services.\n\nPlease do not post link shorteners, link aggregator websites , or auto-subscribe links.\n\n\\--\n\nAny abuse of trust will lead to bans.\n\nEncourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\n\\--\n\nMeta: This is an experiment. If the community doesnt like this, we will cancel it. This is to encourage those in the community to promote their work by not spamming the main threads.",
    "score": 15,
    "comments": 44,
    "created_utc": "2025-09-02T04:15:30",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1n67lft/d_selfpromotion_thread/"
  },
  {
    "id": "1n4jdo7",
    "title": "[D] Monthly Who's Hiring and Who wants to be Hired?",
    "author": "AutoModerator",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1n4jdo7/d_monthly_whos_hiring_and_who_wants_to_be_hired/",
    "text": "**For Job Postings** please use this template\n\n>Hiring: \\[Location\\], Salary:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]    and \\[Brief overview, what you're looking for\\]\n\n**For Those looking for jobs** please use this template\n\n>Want to be Hired: \\[Location\\], Salary Expectation:\\[\\], \\[Remote | Relocation\\], \\[Full Time | Contract | Part Time\\]  Resume: \\[Link to resume\\] and \\[Brief overview, what you're looking for\\]\n\n&#x200B;\n\nPlease remember that this community is geared towards those with experience.",
    "score": 17,
    "comments": 2,
    "created_utc": "2025-08-31T04:30:34",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1n4jdo7/d_monthly_whos_hiring_and_who_wants_to_be_hired/"
  },
  {
    "id": "1nmb8as",
    "title": "[D] NeurIPS: rejecting papers from sanctioned affiliations mid-process",
    "author": "YallenGusev",
    "url": "https://i.redd.it/s55s433k9eqf1.jpeg",
    "text": "I know multiple people and multiple papers who have received this.\n\nIt is probably legally correct. There are legit grounds for these bans.\n\nHowever, I don't think it is okay to do it AFTER reviewing and even accepting the papers. Hundreds of people wasted their time for nothing.\n\nThere was a recent post with messages to SAC about venue constraints, and this might be a way the organizers are solving this problem.",
    "score": 79,
    "comments": 15,
    "created_utc": "2025-09-21T00:16:30",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nmb8as/d_neurips_rejecting_papers_from_sanctioned/"
  },
  {
    "id": "1nmbvi5",
    "title": "[D] ICLR 2026 Submission Count",
    "author": "kipthornberry",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1nmbvi5/d_iclr_2026_submission_count/",
    "text": "I submitted to ICLR after a NeurIPS reject of a borderline paper. My submission id is above 20k! Wondering how many ICLR submissions there are in total (comment if you have a higher sub id) and how much the venue can even accommodate.",
    "score": 16,
    "comments": 10,
    "created_utc": "2025-09-21T00:45:27",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nmbvi5/d_iclr_2026_submission_count/"
  },
  {
    "id": "1nmobs3",
    "title": "[D] mac users, please helpp",
    "author": "Scary-Ad7379",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1nmobs3/d_mac_users_please_helpp/",
    "text": "Started my b.tech degree in aiml, i appreciate the portability that mac offers, so had a few questions...\n\nAbout Mac M4 16gb ram, 256gb ssd, and will be buying an external ssd\n1. Will 16 gb ram be enough?\n\n2. Will i be able to train small models on my own in my free time if yes then how many billion parameter models can I train and use in 16gb M4 varient?\n\n3. Storage 256gb enough?\n\n4. will college provide processing units to train models which are not related to our projects ? Like Just for our own work...eg training our own model?\n\n5. mac 13 inch or 15 inch?",
    "score": 0,
    "comments": 3,
    "created_utc": "2025-09-21T12:17:55",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nmobs3/d_mac_users_please_helpp/"
  },
  {
    "id": "1nlvw1r",
    "title": "[R] MiniGrid DoorKeys Benchmark Active Inference",
    "author": "thomheinrich",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1nlvw1r/r_minigrid_doorkeys_benchmark_active_inference/",
    "text": "I am working on an Active Inference Framework since some time and it has managed to constantly and reproducable perform (I guess) very well on MG-DK without any benchmaxing or training.. the numbers (average) are:\n\n8x8: <19 Steps for SR 1 16x16: <60 Steps for SR 1\n\nDo you know someone or a company or so who might be interested in learning more about this solution or the research involved?\n\nThank you!\n\nBest Thom",
    "score": 9,
    "comments": 5,
    "created_utc": "2025-09-20T13:37:02",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nlvw1r/r_minigrid_doorkeys_benchmark_active_inference/"
  },
  {
    "id": "1nmb7jm",
    "title": "[P] Introducing LabelMob: Connecting ML Teams with Expert Data Annotators",
    "author": "singlasahil14",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1nmb7jm/p_introducing_labelmob_connecting_ml_teams_with/",
    "text": "Hey\u00a0[r/machinelearning](https://www.reddit.com/r/machinelearning/),\n\nI've been working in the ML space for a while and noticed a big pain point: finding high-quality, domain-specific data annotators for complex datasets. Whether it's labeling quantum physics simulations, chemical structures, biological sequences, or advanced mathematical models, generic annotation services often fall short. That's why I built\u00a0[LabelMob.com](https://labelmob.com/)\u00a0\u2013 a platform designed to match companies, universities, and research teams with expert annotators who have real expertise in fields like physics, chemistry, math, biology, data science, and more. How It Works:\n\n* For Hirers (Companies/Universities): Post your annotation projects and specify the expertise needed. We connect you with vetted individuals or specialized annotation companies who can handle niche tasks accurately and efficiently. Think: annotating MRI scans by medical physicists or labeling molecular data by chemists.\n* For Annotators (Experts/Companies): Sign up to showcase your skills and get matched with paid gigs that align with your background. It's a great way for domain experts to monetize their knowledge on a flexible basis.\n\nThe goal is to improve dataset quality for ML models \u2013 we all know garbage in, garbage out, right? Better annotations mean better training data, leading to more reliable AI systems in research and industry.\n\n**Why Now?**\n\nWith the explosion of multimodal and specialized ML applications (e.g., drug discovery, climate modeling, autonomous systems), the demand for expert-level labeling is skyrocketing. LabelMob aims to bridge that gap without the overhead of traditional crowdsourcing platforms.\n\nI'd love feedback from this community! Have you struggled with finding the right annotators? What features would make this more useful for your workflows? Check out the site at\u00a0[labelmob.com](https://labelmob.com/)\u00a0and let me know your thoughts.\n\nDisclaimer: This is a new platform, so we're in early stages and actively iterating based on user input. No spamming intended \u2013 just sharing something I think could help the ML ecosystem.\n\nThanks!",
    "score": 0,
    "comments": 0,
    "created_utc": "2025-09-21T00:15:39",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nmb7jm/p_introducing_labelmob_connecting_ml_teams_with/"
  },
  {
    "id": "1nmo57e",
    "title": "[D] Is peer review overloaded due to rejecting too many papers?",
    "author": "jan_Tamalu",
    "url": "https://i.redd.it/lt36s7a5shqf1.png",
    "text": "The crazy math of queueing theory: When conferences reject a large fraction of papers, many of those submissions come back in the next cycle. But increasing rates a bit reduces drastically the unaccepted paper pool and a percentage of this smaller pool becomes again a similar number of accepted papers as when rates were low! This is not saying we should accept bad papers, the number absolute number of accepted papers changes very little because of the unaccepted pool growth!\n\nSee the interactive model + math: [https://damaru2.github.io/general/queueing\\_to\\_publish\\_in\\_AI\\_or\\_CS/](https://damaru2.github.io/general/queueing_to_publish_in_AI_or_CS/)\n\nWith lower acceptance rates we end up reviewing much more to reach roughly the same number of accepted works.\n\nWhat do you think about this phenomenon? Are we re-reviewing too many papers? Physical constraints can be easily solved with federated conferences (make Eurips an official option for presentation?) or allowing not to present in person.\n\nBonus: Funnel simulation of the ideal case where authors always resubmit their papers [https://i.postimg.cc/gz88S2hY/funnel2.gif](https://i.postimg.cc/gz88S2hY/funnel2.gif) In here you can see that when authors do not give up submitting (that is, the ideal case, but in the post a more complex model is presented), and the number new of papers per round is the same for both cases, the same number of papers are accepted on average per conference in two scenarios with different acceptance rates.",
    "score": 0,
    "comments": 4,
    "created_utc": "2025-09-21T12:06:23",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nmo57e/d_is_peer_review_overloaded_due_to_rejecting_too/"
  },
  {
    "id": "1nlnf5g",
    "title": "[D] AAAI 2026 Phase 2 Review",
    "author": "snu95",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1nlnf5g/d_aaai_2026_phase_2_review/",
    "text": "Hi all,\n\nI\u2019m serving as a reviewer for AAAI \u201926. Has anyone received additional papers for the Phase 2 review yet? The website indicates that Phase 2 starts on Sep. 16, but I haven\u2019t been assigned any papers so far.\n\n[https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic](https://docs.google.com/document/u/0/d/1tqQGwtNUlALPSTqoTo5uTFx8vKuqpILNTne9jeBCOVI/mobilebasic)\n\n\n\nEdit (Sep. 21): Just got assigned three extra papers!",
    "score": 20,
    "comments": 4,
    "created_utc": "2025-09-20T05:15:34",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nlnf5g/d_aaai_2026_phase_2_review/"
  },
  {
    "id": "1nlblaw",
    "title": "[D] Neurips Position Paper Decisions",
    "author": "HelicopterFriendly96",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1nlblaw/d_neurips_position_paper_decisions/",
    "text": "The decisions will be out next week.  \nI am personally not a fan of how the entire process was conducted. Hoping the best for everyone! Please use this as a thread to discuss how you felt about the process. Fingers crossed!",
    "score": 19,
    "comments": 4,
    "created_utc": "2025-09-19T20:33:57",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nlblaw/d_neurips_position_paper_decisions/"
  },
  {
    "id": "1nlfcpq",
    "title": "[P] Building sub-100ms autocompletion for JetBrains IDEs",
    "author": "Kevinlu1248",
    "url": "https://blog.sweep.dev/posts/next-edit-jetbrains",
    "text": "",
    "score": 14,
    "comments": 2,
    "created_utc": "2025-09-19T23:00:53",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nlfcpq/p_building_sub100ms_autocompletion_for_jetbrains/"
  },
  {
    "id": "1nliq67",
    "title": "[P] Benchmarked EpilepsyBench #1 winner - found 27x performance gap, now training Bi-Mamba-2 fix",
    "author": "VibeCoderMcSwaggins",
    "url": "https://www.reddit.com/r/MachineLearning/comments/1nliq67/p_benchmarked_epilepsybench_1_winner_found_27x/",
    "text": "Hey all, been learning EEG ML heavily for the past two months or so.\n\nRecently evaluated SeizureTransformer (#1 on\u00a0[EpilepsyBench\u00a0](https://epilepsybenchmarks.com/challenge/)with \\~1 FA/24h) on the Temple EEG dataset using clinical NEDC scoring:\u00a0**26.89 FA/24h**\u00a0\\- a 27x gap. Same predictions scored three ways produced 8.59 to 136.73 FA/24h depending on methodology alone.\n\n**Evaluation here:**\u00a0[https://github.com/Clarity-Digital-Twin/SeizureTransformer](https://github.com/Clarity-Digital-Twin/SeizureTransformer)  \n[PDF](https://drive.google.com/file/d/1T-lmGZuWr_0YnB0m692ccgVdSRjs_Y5n/view?usp=sharing): Gdrive\n\nSo I can actually contribute instead of reproducing, I'm now training the first\u00a0**Bi-Mamba-2 + U-Net + ResCNN**\u00a0architecture - O(N) complexity while maintaining temporal modeling.\n\n**Training code:**\u00a0[https://github.com/Clarity-Digital-Twin/brain-go-brr-v2](https://github.com/Clarity-Digital-Twin/brain-go-brr-v2)\n\nWould appreciate feedback on either if there is any interest. Also seeking arXiv endorsement for cs.LG if anyone finds this worth sharing (independent researcher).",
    "score": 3,
    "comments": 0,
    "created_utc": "2025-09-20T01:25:34",
    "subreddit": "MachineLearning",
    "permalink": "https://reddit.com/r/MachineLearning/comments/1nliq67/p_benchmarked_epilepsybench_1_winner_found_27x/"
  }
]